{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9eb5a400-29a3-475b-b0fc-528fe7da7b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.models import resnet50, ResNet50_Weights, resnet34, ResNet34_Weights\n",
    "import warnings\n",
    "\n",
    "class resnet_feature_extractor(torch.nn.Module):\n",
    "    def __init__(self, layer2=False, layer3=False, layer4=False):\n",
    "        super(resnet_feature_extractor, self).__init__()\n",
    "        self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.model.eval()\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        def hook(module, input, output):\n",
    "            self.features.append(output)\n",
    "            \n",
    "        # Store user preferences\n",
    "        self.layer2_enabled = layer2\n",
    "        self.layer3_enabled = layer3\n",
    "        self.layer4_enabled = layer4\n",
    "        \n",
    "        # Register hooks dynamically\n",
    "        if self.layer2_enabled:\n",
    "            self.model.layer2[-1].register_forward_hook(hook)\n",
    "        if self.layer3_enabled:\n",
    "            self.model.layer3[-1].register_forward_hook(hook)\n",
    "        if self.layer4_enabled:\n",
    "            self.model.layer4[-1].register_forward_hook(hook)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.features = []\n",
    "        with torch.no_grad():\n",
    "            _ = self.model(input)\n",
    "\n",
    "        self.avg = torch.nn.AvgPool2d(3, stride=1)\n",
    "        fmap_size = self.features[0].shape[-2]\n",
    "        self.resize = torch.nn.AdaptiveAvgPool2d(fmap_size)\n",
    "        resized_maps = [self.resize(self.avg(fmap)) for fmap in self.features]\n",
    "        patch = torch.cat(resized_maps, 1)\n",
    "\n",
    "        return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85e28645-ff1c-429a-b91d-6a656b572c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a284ae19-0dec-4281-9fcc-b122186b679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FeatCAE(nn.Module):\n",
    "    \"\"\"Autoencoder.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=1000, latent_dim=50, is_bn=True):\n",
    "        super(FeatCAE, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(in_channels, (in_channels + 2 * latent_dim) // 2, kernel_size=1, stride=1, padding=0)]\n",
    "        if is_bn:\n",
    "            layers += [nn.BatchNorm2d(num_features=(in_channels + 2 * latent_dim) // 2)]\n",
    "        layers += [nn.ReLU()]\n",
    "        layers += [nn.Conv2d((in_channels + 2 * latent_dim) // 2, 2 * latent_dim, kernel_size=1, stride=1, padding=0)]\n",
    "        if is_bn:\n",
    "            layers += [nn.BatchNorm2d(num_features=2 * latent_dim)]\n",
    "        layers += [nn.ReLU()]\n",
    "        layers += [nn.Conv2d(2 * latent_dim, latent_dim, kernel_size=1, stride=1, padding=0)]\n",
    "\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "        # if 1x1 conv to reconstruct the rgb values, we try to learn a linear combination\n",
    "        # of the features for rgb\n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(latent_dim, 2 * latent_dim, kernel_size=1, stride=1, padding=0)]\n",
    "        if is_bn:\n",
    "            layers += [nn.BatchNorm2d(num_features=2 * latent_dim)]\n",
    "        layers += [nn.ReLU()]\n",
    "        layers += [nn.Conv2d(2 * latent_dim, (in_channels + 2 * latent_dim) // 2, kernel_size=1, stride=1, padding=0)]\n",
    "        if is_bn:\n",
    "            layers += [nn.BatchNorm2d(num_features=(in_channels + 2 * latent_dim) // 2)]\n",
    "        layers += [nn.ReLU()]\n",
    "        layers += [nn.Conv2d((in_channels + 2 * latent_dim) // 2, in_channels, kernel_size=1, stride=1, padding=0)]\n",
    "        # layers += [nn.ReLU()]\n",
    "\n",
    "        self.decoder = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7f44f04-7c3c-49d8-8251-0ed3da8709a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup_cuda():\n",
    "    \"\"\"\n",
    "    Realiza un warmup de CUDA para asegurar que la GPU esté lista.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        # Asegura que CUDA esté inicializado\n",
    "        torch.cuda.synchronize()\n",
    "        # Realiza algunas operaciones dummy para calentar la GPU\n",
    "        dummy = torch.randn(1000, 1000).cuda()\n",
    "        for _ in range(1000):\n",
    "            _ = torch.matmul(dummy, dummy)\n",
    "        torch.cuda.synchronize()\n",
    "        # Limpia la memoria\n",
    "        del dummy\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "warmup_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6469a4c-0da5-4b3a-8bde-593b638da301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 14 12:23:29 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:01:00.0 Off |                  Off |\n",
      "|  0%   39C    P8              58W / 480W |   1187MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b1f72e8-6172-4c14-b545-c1f63a2aa460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on FE Model_l2l3...\n",
      "GPU Memory Allocated: 771.90 MB\n",
      "GPU Memory Cached: 820.00 MB\n",
      "GPU Memory Allocated: 787.90 MB\n",
      "GPU Memory Cached: 870.00 MB\n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  model_inference        29.60%       1.532ms       100.00%       5.177ms       5.177ms     627.000us        12.10%       5.180ms       5.180ms           0 b           0 b      16.00 Mb    -474.01 Mb             1  \n",
      "                 aten::batch_norm         2.27%     117.389us        41.05%       2.125ms      40.099us     119.000us         2.30%       2.034ms      38.377us           0 b           0 b     231.50 Mb           0 b            53  \n",
      "     aten::_batch_norm_impl_index         2.81%     145.247us        38.78%       2.008ms      37.885us     132.000us         2.55%       1.915ms      36.132us           0 b           0 b     231.50 Mb           0 b            53  \n",
      "                     aten::conv2d         2.16%     112.029us        21.10%       1.092ms      20.610us     122.000us         2.36%       1.891ms      35.679us           0 b           0 b     230.50 Mb           0 b            53  \n",
      "           aten::cudnn_batch_norm        25.32%       1.311ms        35.98%       1.863ms      35.144us       1.064ms        20.54%       1.783ms      33.642us           0 b           0 b     231.50 Mb           0 b            53  \n",
      "                aten::convolution         2.52%     130.700us        18.94%     980.321us      18.497us     142.000us         2.74%       1.769ms      33.377us           0 b           0 b     230.50 Mb           0 b            53  \n",
      "               aten::_convolution         3.18%     164.440us        16.41%     849.621us      16.031us     144.000us         2.78%       1.627ms      30.698us           0 b           0 b     230.50 Mb     -19.60 Mb            53  \n",
      "          aten::cudnn_convolution        13.23%     685.181us        13.23%     685.181us      12.928us       1.483ms        28.63%       1.483ms      27.981us           0 b           0 b     250.10 Mb     250.10 Mb            53  \n",
      "                      aten::empty         7.79%     403.324us         7.79%     403.324us       1.894us     523.000us        10.10%     523.000us       2.455us           0 b           0 b     223.50 Mb     223.50 Mb           213  \n",
      "                 aten::empty_like         2.47%     127.960us         9.41%     487.422us       9.197us     131.000us         2.53%     455.000us       8.585us           0 b           0 b     231.50 Mb       8.00 Mb            53  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.177ms\n",
      "Self CUDA time total: 5.180ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W114 12:23:41.793038913 kineto_shim.cpp:405] Adding profiling metadata requires using torch.profiler with Kineto support (USE_KINETO=1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.profiler\n",
    "import time\n",
    "\n",
    "# MODIFY THE BELOW PARAMS\n",
    "fe_model = resnet_feature_extractor(layer2=True) # Load the feature extraction model\n",
    "cae_model = FeatCAE(in_channels=512, latent_dim=100)\n",
    "torch_state = torch.load('/home/jovyan/work/anomaly_detection_demo/modelsave/model.pth')\n",
    "cae_model.load_state_dict(torch_state['model_state_dict'])\n",
    "# Load the pre-trained CAE model\n",
    "\n",
    "# Move models to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "fe_model.to(device)\n",
    "cae_model.to(device)\n",
    "\n",
    "# Dummy input image for testing\n",
    "dummy_input = torch.randn(1, 3, 512, 512).to(device)  # Replace with actual input dimensions\n",
    "\n",
    "# Measure GPU usage before starting the process\n",
    "def log_gpu_usage():\n",
    "    print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    print(f\"GPU Memory Cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Start profiler to log inference time\n",
    "def run_inference_with_profiler(model, input_data, model_name, output_dir):\n",
    "    # Log GPU usage before inference\n",
    "    print(f\"Running inference on {model_name}...\")\n",
    "    log_gpu_usage()\n",
    "\n",
    "    # Profile the inference time\n",
    "    with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        profile_memory=True,\n",
    "    ) as prof:\n",
    "        with torch.profiler.record_function(\"model_inference\"):\n",
    "            with torch.no_grad():\n",
    "                output=model(input_data)\n",
    "                    \n",
    "            # Log GPU usage after inference\n",
    "            log_gpu_usage()\n",
    "        \n",
    "    # Print the profiling results\n",
    "    print(prof.key_averages().table(\n",
    "        sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", \n",
    "        row_limit=10\n",
    "    ))\n",
    "\n",
    "    csv_path = os.path.join(output_dir, f'{model_name}_profiler_results.csv')\n",
    "    with open(csv_path, 'w') as f:\n",
    "        # Write CSV header\n",
    "        f.write(\"Operation,CPU Time (ms),CUDA Time (ms),Called,CPU Memory (MB) ,CUDA Memory (MB)\\n\")\n",
    "        \n",
    "        # Export detailed results\n",
    "        for row in prof.key_averages():\n",
    "            f.write(\n",
    "                f\"{row.key},\"\n",
    "                f\"{row.cpu_time_total/1000:.2f},\"\n",
    "                f\"{row.cuda_time/1000:.2f},\"\n",
    "                f\"{row.count},\"\n",
    "                f\"{row.cpu_memory_usage/1024/1024:.2f},\"\n",
    "                f\"{row.self_device_memory_usage/1024/1024:.2f}\\n\"\n",
    "            )\n",
    "            \n",
    "    return output, prof\n",
    "\n",
    "# Run inference on the FE model\n",
    "fe_output, fe_profiler = run_inference_with_profiler(fe_model, dummy_input, \"FE Model_l2l3\", \"/home/jovyan/work/anomaly_detection/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81e1c160-d4b6-41c3-af77-ed5ea4c700ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on CAE Model_l2l3...\n",
      "GPU Memory Allocated: 239.81 MB\n",
      "GPU Memory Cached: 870.00 MB\n",
      "GPU Memory Allocated: 247.81 MB\n",
      "GPU Memory Cached: 870.00 MB\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 model_inference        48.30%     533.868us       100.00%       1.105ms       1.105ms     451.000us        40.74%       1.107ms       1.107ms           0 b           0 b       8.00 Mb     -54.25 Mb             1  \n",
      "                    aten::conv2d         1.80%      19.913us        28.35%     313.312us      52.219us      18.000us         1.63%     381.000us      63.500us           0 b           0 b      27.25 Mb           0 b             6  \n",
      "               aten::convolution         2.55%      28.216us        26.55%     293.399us      48.900us      27.000us         2.44%     363.000us      60.500us           0 b           0 b      27.25 Mb           0 b             6  \n",
      "              aten::_convolution         6.49%      71.746us        23.99%     265.183us      44.197us      46.000us         4.16%     336.000us      56.000us           0 b           0 b      27.25 Mb           0 b             6  \n",
      "         aten::cudnn_convolution        12.24%     135.297us        12.24%     135.297us      22.550us     228.000us        20.60%     228.000us      38.000us           0 b           0 b      27.25 Mb      27.25 Mb             6  \n",
      "                aten::batch_norm         1.50%      16.626us        18.63%     205.935us      51.484us      12.000us         1.08%     210.000us      52.500us           0 b           0 b      17.50 Mb     -10.00 Kb             4  \n",
      "    aten::_batch_norm_impl_index         1.70%      18.828us        17.13%     189.309us      47.327us      17.000us         1.54%     198.000us      49.500us           0 b           0 b      17.51 Mb           0 b             4  \n",
      "          aten::cudnn_batch_norm        11.61%     128.325us        15.42%     170.481us      42.620us     121.000us        10.93%     181.000us      45.250us           0 b           0 b      17.51 Mb           0 b             4  \n",
      "                      aten::add_         4.95%      54.736us         4.95%      54.736us       5.474us      63.000us         5.69%      63.000us       6.300us           0 b           0 b           0 b           0 b            10  \n",
      "                      aten::relu         1.33%      14.693us         3.01%      33.311us       8.328us      12.000us         1.08%      43.000us      10.750us           0 b           0 b      17.50 Mb           0 b             4  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.105ms\n",
      "Self CUDA time total: 1.107ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W114 12:23:44.925109263 kineto_shim.cpp:405] Adding profiling metadata requires using torch.profiler with Kineto support (USE_KINETO=1)\n"
     ]
    }
   ],
   "source": [
    "cae_output, cae_profiler = run_inference_with_profiler(cae_model, fe_output, \"CAE Model_l2l3\", \"/home/jovyan/work/anomaly_detection/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning]",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
