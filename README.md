
# Anomaly Detection

## ğŸ“‹ DescripciÃ³n
Modelo de detecciÃ³n de anomalÃ­as basado en autoencoders convolucionales (CAE), entrenado Ãºnicamente con imÃ¡genes OK para identificar imÃ¡genes KO mediante reconstrucciÃ³n y anÃ¡lisis de desviaciones. Enfoque semi-supervisado diseÃ±ado para aplicaciones de control de calidad.

## ğŸš€ Inicio RÃ¡pido

### InstalaciÃ³n

1. Clonar el repositorio:
```bash
git clone <URL-del-repositorio>
cd anomaly-detection
```

2. Preparar datos en un formato como se demuestra en el esquema (incluidos los nombres de  directorios) para entrenamiento con imÃ¡genes OK:

```shell
${BASE_DIR}/train
â”œâ”€â”€ good
â”‚   â”œâ”€â”€ 000000000.jpg
â”‚   â”œâ”€â”€ 000000001.jpg
â”‚   â”œâ”€â”€ 000000002.jpg
â”‚   â””â”€â”€ ... (more images)
```
3. Repetir el procedimiento para imÃ¡genes KO:
```shell
${BASE_DIR}/test
â”œâ”€â”€ good
â”‚   â”œâ”€â”€ 000000032.jpg
â”‚   â”œâ”€â”€ 000000033.jpg
â”‚   â”œâ”€â”€ 000000034.jpg
â”‚   â””â”€â”€ ... (more images)
â”œâ”€â”€ bad
â”‚   â”œâ”€â”€ 0000000112.jpg
â”‚   â”œâ”€â”€ 0000000113.jpg
â”‚   â”œâ”€â”€ 0000000114.jpg
â”‚   â””â”€â”€ ... (more images)
```
â—Es importante aÃ±adir imÃ¡genes OK para el conjunto de entrenamiento para asegurarse de que el modelo los identifica de los imÃ¡genes KO

4. Modificar el config.yaml con los datos necesarios:
```yaml
paths:
  train_path: "ruta_del_conjunto_train"
  test_path: "ruta_del_conjunto_test"
  output_path: "ruta_para_guardar_outputs_y_grÃ¡ficas"
  model_save_path: "ruta_para_guardar_modelo"
```

## ğŸ’» Uso

### EjecuciÃ³n del script para entrenamiento y validaciÃ³n
```bash
python /anomaly-detection/main.py --config="ruta_del_config" --mode=full --test_path="ruta_del_conjunto_test" --model_path="ruta_para_guardar_modelo" --output_dir="ruta_para_guardar_outputs_y_grÃ¡ficas"
```
### Perfilado avanzado del modelo usando Pytorch.profiler con performance.ipynb
```python
# MODIFY THE BELOW PARAMS
fe_model = resnet_feature_extractor(layer2=True) # Load the feature extraction model 
cae_model = FeatCAE(in_channels=512, latent_dim=100)
torch_state = torch.load('/home/jovyan/work/anomaly_detection_demo/modelsave/model.pth')
cae_model.load_state_dict(torch_state['model_state_dict'])
```
- Dentro de FE model es posible definir las capas con las que se van a extraer las caracterÃ­sticas (layer2, layer3 y layer4) para ello es necesario poner la capa que se necesite a True.
- De la configuraciÃ³n elegida anteriormente depende el tamaÃ±o de entrada al modelo FeatCAE(in_channels=X)
- Para cambiar de un modelo entrenado a otro solo hace falta cambiar la ruta de torch_state

<details>
<summary> Tabla de in_channels basada en elecciÃ³n de capas: </summary>
  
| Layer2 | Layer3 | Layer4 | in_channels |
| :---: | :---: | :---: | :---: |
| True | False | False |  512 |
| False | True | False | 1024 |
| False | False | True | 2048 |
| True | True | False | 1536 |
| True | False | True | 2560 |
| False | True | True | 3072 |
| True | True | True | 3584 |

</details>


torch.profiler es una herramienta de perfilado avanzada que permite analizar el rendimiento de modelos PyTorch, proporcionando informaciÃ³n detallada sobre:

ProfilerActivity.CPU: Operaciones realizadas en CPU
ProfilerActivity.CUDA: Operaciones realizadas en GPU
Tiempos de ejecuciÃ³n
Uso de memoria
Trazas de operadores

Tanto para el extractor de caracterÃ­sticas como para el modelo de extracciÃ³n de caracterÃ­sticas como del modelo de tipo Autoencoder los resultados se guardan en formato .csv en el directorio de los outputs:
<div align="center">
  <img src="https://github.com/user-attachments/assets/cec2d05c-6016-4164-9f05-aad0cffb619f" alt="Description" width="600">
</div>

## ğŸ› ï¸ Funcionalidades Principales

- DetecciÃ³n de anomalÃ­as mediante autoencoder convolucional
- ExtracciÃ³n de caracterÃ­sticas usando ResNet50 pre-entrenado
- Entrenamiento configurable mediante archivo YAML
- VisualizaciÃ³n de mapas de calor para anomalÃ­as
- Pipeline completo de entrenamiento y evaluaciÃ³n
- Soporte para GPU y CPU

## ğŸ“Š VisualizaciÃ³n de Resultados
Los resultados se guardan automÃ¡ticamente, incluyendo:
- Curvas de pÃ©rdida de entrenamiento y validaciÃ³n
- Curva ROC y mÃ©tricas de evaluaciÃ³n
- Mapas de calor de anomalÃ­as detectadas
- VisualizaciÃ³n de imÃ¡genes con superposiciÃ³n de detecciones

## ğŸ”§ CaracterÃ­sticas TÃ©cnicas
- Backbone: ResNet50 con extracciÃ³n de caracterÃ­sticas multicapa
- Detector: Autoencoder convolucional personalizado
- Umbral adaptativo basado en estadÃ­sticas de reconstrucciÃ³n
- Soporte para procesamiento por lotes
- VisualizaciÃ³n personalizable de resultados


## ğŸ–¥ï¸ Interfaz grÃ¡fica con Gradio 

  Se ejecuta mediante:
```bash
python gradio-app.py
```
La interfaz da la posibilidad de cargar imÃ¡genes y entrenar un modelo con las imÃ¡genes OK:
![image](https://github.com/user-attachments/assets/03dbbe25-a9a3-4c39-8a88-3f86b8c74bc3)

AdemÃ¡s, se puede realizar inferencia y devolver predicciones sobre imÃ¡genes KO con sus mapas de calor asociadas:
![image](https://github.com/user-attachments/assets/d877be12-bc47-4f9f-9383-3b3c3423ef39)
